{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONsLxkOHmYowlDxyePvdy4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/pytorch_exercises/blob/master/Pytorch_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Fundamentals**"
      ],
      "metadata": {
        "id": "GeVKwrD9e1fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H-gpsch1JqgC",
        "outputId": "54c95288-d940-48ba-9529-1c11c15f7f29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.0+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating tensors"
      ],
      "metadata": {
        "id": "mCY2WnjBKSJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XB58rSXKWg5",
        "outputId": "9ff5a0a3-5866-4fdf-8b21-110d7f17c22c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht_PDSpDKqTP",
        "outputId": "2157a40d-7db0-403b-bebd-29654ca46ddd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Python number within a one-element tensor\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGAaXxeYKy-t",
        "outputId": "311d778d-4c6b-418e-d762-253504efcf62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTf-XvQ4LJeY",
        "outputId": "79388de6-8070-42e7-bbd8-addeb5c05f04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the number of dimensions of vector\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ls9t3MfMGXf",
        "outputId": "0cca27a0-7511-4535-c628-436a7072e5b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of vector\n",
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVfGSd2VMNh7",
        "outputId": "8e1ffa97-9bb8-48aa-b7a6-1d0d340a3958"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "matrix = torch.tensor([[7, 8],\n",
        "                      [9, 10]])\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDlOO8wyMZha",
        "outputId": "24f857b4-4140-4420-e1f8-2377ccefdf68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZOCilw9NVpJ",
        "outputId": "559203ed-28eb-432e-bb12-374671fcbfb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku7AY6okNezA",
        "outputId": "44ae34c3-e454-4851-c901-5e5ac7140b68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGUrMxSMOD_R",
        "outputId": "8b09a973-0e29-495f-af1f-c8aec18a6112"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bDCBJhqJb9J",
        "outputId": "7f0e7b13-04da-42cd-c1e4-d3871227d855"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMXCzGODKIuy",
        "outputId": "80073157-869f-4e72-a6bf-345960d1455a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-9gcon1KQ_O",
        "outputId": "4b6ae70d-620c-419d-b4cd-970b64f158f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3954, 0.2482, 0.1840, 0.4183],\n",
              "         [0.2358, 0.4690, 0.7092, 0.9435],\n",
              "         [0.3703, 0.8319, 0.7826, 0.4327]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw_VzigpLJne",
        "outputId": "a1b2ee32-1ab9-4cec-b6e4-521ca6469a25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZhm_OEWuBPA",
        "outputId": "46438b68-f66e-47ee-df15-2a04dc9d217d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfDN_HgpuWgp",
        "outputId": "e1b0adff-26f4-43b1-cb56-75148dc3e9fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.arange(). \n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1D-aHd_umLn",
        "outputId": "bec77a39-7fdd-4510-a62c-e1429930c9f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8gnypeWvfCL",
        "outputId": "784cbc83-8d80-46e6-c95b-386fea914a09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # Defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # Defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywpZVfPaNM5k",
        "outputId": "81cc3cd5-3351-4b51-d4ab-130619b285ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze9rvMLtsMA9",
        "outputId": "3340751b-948b-446a-e278-227d433927e8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor and find out details about it\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about the tensor\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KejiHuLGtQHG",
        "outputId": "df8d07fd-f5d6-40ac-dfc9-9429538eb438"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9623, 0.4131, 0.9520, 0.5421],\n",
            "        [0.5866, 0.6971, 0.4507, 0.3493],\n",
            "        [0.9613, 0.6656, 0.0833, 0.8002]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
        "int_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJKkW2W7mfiW",
        "outputId": "a2e95f9a-fdf6-4f7a-831b-76d7f15d4ed2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor * int_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JOHAmzUnUHl",
        "outputId": "2c7f1c1b-a28d-4254-958f-d944d08cafdf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tensor Ops**"
      ],
      "metadata": {
        "id": "UJzZgJ-AujUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzuX54i_uo18",
        "outputId": "b950ee23-3d75-463c-a6bb-4d2c09a30956"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrORO0eCeTGi",
        "outputId": "63f49bc8-ac28-409c-ee71-260ce6a7ae38"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors don't change unless they are reassigned\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7wsPa1Ofmb8",
        "outputId": "87f641c9-f471-424b-aea1-6e16e9ded49b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkQP1jSTfxxj",
        "outputId": "492b084b-40bb-4984-abce-cb718edb7e51"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zctJ4jl-f_Sa",
        "outputId": "dc085f2b-7ee2-438d-cc81-01987ba90b2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use built-in pytorch functions\n",
        "torch.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz339WwcgKsb",
        "outputId": "0505ad74-a0ac-42aa-ccc1-89ae00ce830b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original tensor is still unchanged\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-KuZWEgglZ",
        "outputId": "0b68aada-87fc-4e66-ea78-219bbc77af1f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_KsHNMAgpba",
        "outputId": "03c3d9aa-3cb8-4dd5-d392-18a814e4df31"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication and matrix multiplication\n",
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRXqfuxLhSmj",
        "outputId": "236df6ab-1cb0-4496-876a-b804308756a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise and matrix multiplication\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCss_vq0h8tS",
        "outputId": "72fb7ab8-4581-4c29-e744-4e9d91d63637"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplicatiion\n",
        "torch.matmul(tensor, tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnCDmmbDiKK1",
        "outputId": "4dafaac7-788f-4689-8558-fa559f089f94"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A not so recommended symbol for matrix multiplication\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhxWxeZniaey",
        "outputId": "86ab1903-9ff6-4592-9218-48ddc5acb19c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cg5dOyoiose",
        "outputId": "179caf5a-42ea-40db-f3dc-a9f6ccc77af5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.3 ms, sys: 0 ns, total: 2.3 ms\n",
            "Wall time: 2.55 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpBRR08OkC_M",
        "outputId": "a2f1276c-8a7b-4753-ffc0-7cad79057dad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 29 µs, sys: 0 ns, total: 29 µs\n",
            "Wall time: 32.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # inner dimensions need to match for matrix multiplication to work\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# torch.matmul(tensor_A, tensor_B) # this won't work because the inner dimensions don't match"
      ],
      "metadata": {
        "id": "vqAVHez1mKvO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When inner dimensions don't match, you can use the transpose function to enable the multiplication work\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)\n",
        "\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou7HNOvKndw2",
        "outputId": "5f78c626-5f4a-44d8-8078-70d003a12092"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVue0Ps-qC1u",
        "outputId": "a28c00fd-8bd7-45cb-ac07-2db19da281e1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1KFzcL6Ja7A",
        "outputId": "86361c63-e109-4209-f7ef-4717338f584c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find max, min, sum, etc. (aggregation)\n",
        "print(f\"Minumum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this gives us an error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # wont work w/o float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfBTK3x5ps6I",
        "outputId": "9c79fdc2-1ca1-4e4c-e3e7-a4222bc3ecee"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minumum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzSTejsCq_bL",
        "outputId": "3ecc7940-7a42-4c04-ac33-56aef9746c61"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Positional min/max\n",
        "\n",
        "#create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Return index of max & min vals\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCu-2dJbrz9A",
        "outputId": "aaa5ecab-d6a1-4f9b-dc2a-cbe8856a5c06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change tensor datatype\n",
        "\n",
        "#create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GcQpULl3s1j",
        "outputId": "6df47bd4-b949-417d-9115-64de8999ddee"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99flcER_4Lar",
        "outputId": "da40f402-6148-4628-cc31-a0a2f127dcd5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M18Dvxu54dCg",
        "outputId": "c8fe5767-361a-4ec5-d3b5-530ba8e77243"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESHAPING, STACKING, SQUEEZING & UNSQUEEZING\n",
        "\n",
        "#create a tensor\n",
        "import torch\n",
        "\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNEgSq705DFA",
        "outputId": "b70da66e-acab-4373-e194-f62e95a8496a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's add an extra dimension w/ torch.reshape()\n",
        "\n",
        "#Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up9hlAvh5q7l",
        "outputId": "ec93ed6d-f756-4df0-f717-59d88d19bf57"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's change the view with torch.view()\n",
        "\n",
        "#Change view (keeps same data as original but changes view)\n",
        "z = x.view(1, 7)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL7K6Z-Q6Gw3",
        "outputId": "bb6dee30-6c61-4e34-a306-d5dfd93062be"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jBREJJ-9Pp5",
        "outputId": "1910fb24-ecde-4f1e-d47e-f782eefbc0cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other five times\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE9zZ3B_91jX",
        "outputId": "ff5d5db8-c644-4430-e11e-1d866601a0e7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try changing dim to dim=1\n",
        "x_stacked = torch.stack([x, x, x, x], dim=1) \n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trwX3yga-OlE",
        "outputId": "86fd2ad6-e8a6-481a-b79b-5a84121ad121"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing all single dimensions from a tensor\n",
        "\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Rename extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtnE61qF_0is",
        "outputId": "01741778-5fb6-4233-ed55-07f9fb4f71ae"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a dimension value of 1 at a specific index\n",
        "# torch.unsqueeze()\n",
        "\n",
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tcmNmxzDIrU",
        "outputId": "4a13402a-11eb-40f9-eee7-8ad37c35977f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Previous shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "New shape: torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor w/ specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxFx_8dFE5lw",
        "outputId": "c9fb88a1-cdbf-4495-b014-6e2cd42a1008"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing (selecting data from tensors)\n",
        "\n",
        "#Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45mJmhgKfPpo",
        "outputId": "21d05e4d-1192-4c6a-e07a-dbcef3f17bdc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]), torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How to index bracket by bracket\n",
        "#indexing vals goes from outer dimension -> inner dimension\n",
        "\n",
        "print(f\"First square bracket: \\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFx8lR-LfyUR",
        "outputId": "8cf4d916-2dd9-43c8-985a-dd365c2ad445"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the middle bracket\n",
        "x[0, 0], x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZkPpjadLwyd",
        "outputId": "4f1c51a5-bcb4-440a-a25a-06ee34734ffe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-IE96BPkApH",
        "outputId": "536d9c12-0d8a-4423-ac7e-e1abb876e3aa"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th & 1st dimension but only the index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d_SreDBkP09",
        "outputId": "100755f2-68fa-4a4a-9771-b31aa782c0c1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwjsL1n6_RQh",
        "outputId": "f070c4f8-f276-4988-8273-b9f7e4551a7a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index 0 of 0th and last dimension and all values of 2nd dimension\n",
        "x[0, 0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9XHE9WgIt-r",
        "outputId": "452218d7-aae1-4d33-d16a-420262fdc08a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PYTORCH TENSORS & **NUMPY**"
      ],
      "metadata": {
        "id": "wkjjC0mMJi1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "# tensor = torch.from_numpy(array) .type(torch.float32)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5SwrURrJrhd",
        "outputId": "acb8d66d-a2b5-4d80-b706-0b5799106c10"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ],
      "metadata": {
        "id": "kCUfbjibxO_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the array, keep the tensor\n",
        "array = array + 1\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLphR5VDwxGw",
        "outputId": "ffe529ee-c4e9-4ca8-ef0b-dc0d6d3a3afb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to go from PyTorch tensor to NumPy array, you can call `tensor.numpy()`"
      ],
      "metadata": {
        "id": "_6VUH2dbxTRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2yGGNAFxgCu",
        "outputId": "39406062-e228-42ff-c6db-6800e0447d9e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the tensor, keep the array the same\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1lcubVHz9P0",
        "outputId": "96f51bc6-a14f-4445-d2dd-41faa9fa4e13"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducability\n",
        "\n",
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se0oPL9x2L7P",
        "outputId": "d0eaf412-b7f0-4c0b-b3e8-b22e25fa0a7e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.3018, 0.6730, 0.3412, 0.0996],\n",
            "        [0.8262, 0.5775, 0.0666, 0.6188],\n",
            "        [0.7690, 0.1713, 0.2723, 0.7772]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.2263, 0.9708, 0.9505, 0.1136],\n",
            "        [0.6960, 0.0692, 0.1232, 0.9624],\n",
            "        [0.4810, 0.6903, 0.1957, 0.3777]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To make random but reproducible tensors\n",
        "import torch\n",
        "# Set the random seed\n",
        "RANDOM_SEED=45\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# HAve to reset the seed every time a new rand() is called\n",
        "# W/O this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) \n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor_C equal Tensor_D?(anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1yJNI0S32aw",
        "outputId": "20eff962-df32-4372-8221-4ded88a1129a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.1869, 0.9613, 0.6834, 0.8988],\n",
            "        [0.0505, 0.5555, 0.7861, 0.0566],\n",
            "        [0.7842, 0.1480, 0.0388, 0.1037]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.1869, 0.9613, 0.6834, 0.8988],\n",
            "        [0.0505, 0.5555, 0.7861, 0.0566],\n",
            "        [0.7842, 0.1480, 0.0388, 0.1037]])\n",
            "\n",
            "Does Tensor_C equal Tensor_D?(anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi`"
      ],
      "metadata": {
        "id": "WmjhLlOWBpZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check if you've got access to a Nvidia GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_OsthLFBF-n",
        "outputId": "b64388f1-5ddf-4602-c681-979fff413037"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan  4 17:34:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting PyTorch to run on the GPU"
      ],
      "metadata": {
        "id": "b-kfUXF2Ckdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOf4JGCTCl45",
        "outputId": "438a2221-2a0e-4be7-8945-0d759050dd84"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a device variable to store what kind of device is available.\n",
        "\n",
        "#Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EoCx0Kx6C16v",
        "outputId": "60136dd1-f743-4626-9577-1f3505ad64b6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C8C9jYeDV7O",
        "outputId": "77613a32-60a7-48c6-9ea4-e8c4dd3b87e5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting tensors (and models) on the GPU**\n",
        "\n",
        "You can put tensors on a specific device by calling to\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "(device) on them."
      ],
      "metadata": {
        "id": "jb75c7EjDkg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor and putting it on the GPU (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLbFUdVSDpr6",
        "outputId": "f105207b-f5cc-409e-f7b0-aabc268af7e5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving tensors back to the CPU**"
      ],
      "metadata": {
        "id": "YIqNopcaE3z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (will give error)\n",
        "\n",
        "# tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "id": "bKCHGIqFFDkd"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy we can use `Tensor.cpu()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "lKtjvpLCFc-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyp8YGUEFadB",
        "outputId": "a724538f-6d2f-4078-f5ff-99078fdaf729"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ],
      "metadata": {
        "id": "lc3f7vZvF6Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQrn4DYSF9tJ",
        "outputId": "1d5b7ba3-da3e-496d-aa24-c9d24afa3e27"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Workflow Fundamentals**"
      ],
      "metadata": {
        "id": "UL0qSFsGhdEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TtiDZA1yhlKB",
        "outputId": "91b5aaea-56ee-4819-efd2-2a5c6a11f02a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.0+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Prep & Loading"
      ],
      "metadata": {
        "id": "3fX2EaQHp05K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create known parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "x = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * x + bias\n",
        "\n",
        "x[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K8Tb2zEp4tq",
        "outputId": "92d73b0f-b98c-49fe-9bb2-0041f1754cf0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]), tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into training and test sets"
      ],
      "metadata": {
        "id": "0Mf12eqOHfHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we build a modelthat can learn the relationship between x (features) and y (labels), we need to split our data into a training and a test set(& when needed, a validation set)."
      ],
      "metadata": {
        "id": "QEzi3hb3HkvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split\n",
        "train_split = int(0.8 * len(x)) # 80% of data used for training set, 20% for testing set\n",
        "x_train, y_train = x[:train_split], y[:train_split]\n",
        "x_test, y_test = x[train_split:], y[train_split:]\n",
        "\n",
        "len(x_train), len(y_train), len(x_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBlqICsPIvY9",
        "outputId": "64fe3d51-9a88-4db1-85f8-f8d1d32b5af5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to visualize data"
      ],
      "metadata": {
        "id": "4sptUqYILTkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=x_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=x_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  plots training data, test data & compares predictions\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "WevJ6ykHLcmq"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "p-owKIyoTfei",
        "outputId": "0006a854-ad5d-4d2d-f5ac-4ccbdd0a73e5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "PLni7Ui-WQ5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll build a model to use the blue dots to predict the green dots.\n",
        "\n",
        "Let's start by replicating a standard linear regression model using pure PyTorch."
      ],
      "metadata": {
        "id": "DNCyCpaKWaN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Linear Regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
        "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                requires_grad=True) # <- can we update this value with gradient descent?)\n",
        "\n",
        "    self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
        "                                            dtype=torch.float), # <- PyTorch defaults to float32\n",
        "                             requires_grad=True) # <- can we update this value with gradient descent?))\n",
        "\n",
        "  # Forward defines the computation in the model\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
        "      return self.weights * x * self.bias # <- this is the linear regression formula (y = m*x + b)"
      ],
      "metadata": {
        "id": "snL96V5JW2yM"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a model instance with the class we've made & check it's parameters using `.parameters()`"
      ],
      "metadata": {
        "id": "0YcsNXbGiKfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set manual seed since nn.Parameter are randomly initialized\n",
        "torch.manual_seed(38)\n",
        "\n",
        "# Create an instance of the model ( this is a subclass of nn.Module that contains nn.Parameter(s))\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmiax150iJmH",
        "outputId": "29088cac-53ea-4589-83ec-f04725e9058a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([1.5060], requires_grad=True), Parameter containing:\n",
              " tensor([0.1456], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get the state(i.e. the content of the model) of the model using `.stat_dict()`"
      ],
      "metadata": {
        "id": "uytBBNuxjW0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4LpEPJTjpiA",
        "outputId": "f7f8d2e0-ff8d-42a8-d5db-e1a12c02a2da"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([1.5060])), ('bias', tensor([0.1456]))])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions using `torch.inference_mode()`"
      ],
      "metadata": {
        "id": "4GmKXW1QkpH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO check this we can pass in the test data X_test to see how closely it predicts y_test.\n",
        "\n",
        "When we pass data to our model, it'll go through the model's `forward()` method and produce a result using the computation we've defined."
      ],
      "metadata": {
        "id": "fV7vhHF8FAfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():  # this is a context manager--we use it to make predictions(i.e. inference)\n",
        "  y_preds = model_0(x_test)"
      ],
      "metadata": {
        "id": "z_N_uzuWFsud"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the predictions\n",
        "print(f\"Number of testing samples: {len(x_test)}\")\n",
        "print(f\"Number of predictions made: {len(y_preds)}\")\n",
        "print(f\"Predicted values:\\n{y_preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itz4zF9a7Rx7",
        "outputId": "7f9969e6-9f69-43c5-ecc0-d74bf92a7cbe"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing samples: 10\n",
            "Number of predictions made: 10\n",
            "Predicted values:\n",
            "tensor([[0.1754],\n",
            "        [0.1798],\n",
            "        [0.1842],\n",
            "        [0.1885],\n",
            "        [0.1929],\n",
            "        [0.1973],\n",
            "        [0.2017],\n",
            "        [0.2061],\n",
            "        [0.2105],\n",
            "        [0.2148]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Let's visualize our predictions with the `plot_predictions()` function we created above."
      ],
      "metadata": {
        "id": "f5Nz3yfa8W4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "WG7HbZfe8ifO",
        "outputId": "8d6766fe-4c01-4d32-e209-c8cfc5b3164f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test - y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy8TTe4K8x0g",
        "outputId": "e7f41c2a-8fd6-43e7-d52a-ce6615c874ae"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6846],\n",
              "        [0.6942],\n",
              "        [0.7038],\n",
              "        [0.7135],\n",
              "        [0.7231],\n",
              "        [0.7327],\n",
              "        [0.7423],\n",
              "        [0.7519],\n",
              "        [0.7615],\n",
              "        [0.7712]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our predictions look pretty bad since our model is just using random parameter values to make predictions. It needs to look at the blue dots to try to predict the green dots. We do this by training our model."
      ],
      "metadata": {
        "id": "ZHgU8Onn87h5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train model"
      ],
      "metadata": {
        "id": "nAsB55pW9X6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now our model is using random parameters to make calculations. It's guessing blindly.\n",
        "\n",
        "To fix that we can update its internal params/patterns, the weights & bias values we set randomly using `nn.Parameter()` & `torch.randn()` to be something that better represents the data.\n",
        "\n",
        "Most times we won't know what the ideal params are for a model, instead we write code to see if the model can try & figure them out itself."
      ],
      "metadata": {
        "id": "qsLxbyLZ98DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a loss function and optimizer in PyTorch"
      ],
      "metadata": {
        "id": "fd6nZspW-6Vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our model to update its params on its own, we'll need to add a **loss function** & an **optimizer** to it."
      ],
      "metadata": {
        "id": "Fv-LOVZk_Dzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Loss function**\tMeasures how wrong your models predictions (e.g. y_preds) are compared to the truth labels (e.g. y_test). The Lower the better.\t\n",
        "\n",
        "PyTorch has plenty of built-in loss functions in torch.nn.\t\n",
        "\n",
        "Some common loss function values are: Mean absolute error (MAE) for regression problems (`torch.nn.L1Loss()`). Binary cross entropy for binary classification problems (`torch.nn.BCELoss()`).\n",
        "\n",
        "**Optimizer**\tTells your model how to update its internal parameters to best lower the loss.\n",
        "\n",
        "You can find various optimization function implementations in `torch.optim`.\n",
        "\n",
        "Some common optimizer values are: Stochastic gradient descent (torch.optim.SGD()). Adam optimizer (torch.optim.Adam())."
      ],
      "metadata": {
        "id": "QvNC4c8h_0Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets create a loss function & an optimizer we can use to improve out model."
      ],
      "metadata": {
        "id": "og5NdIypC935"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the loss function\n",
        "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
        "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
      ],
      "metadata": {
        "id": "3iexytxZ9ig8"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an optimization loop in PyTorch\n",
        "\n",
        "The next step is to create a training and a testing loop for our model.\n",
        "\n",
        "The training loop involves the model going through the training data and learning the relationships between the `features` and `labels`.\n",
        "\n",
        "The testing loop involves going through the testing data and evaluating how good the patterns are that the model learned on the training data(the model never sees the testing data during training).\n",
        "\n",
        "We'll use a Python `for` loop to accomplish this step."
      ],
      "metadata": {
        "id": "nMoyJpcbDqU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs (the number of times the model will pass over the training data)\n",
        "epochs = 100\n",
        "\n",
        "# Create empty loss lists to track values\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs)\n",
        "    ### Training\n",
        "\n",
        "    # Put model in training mode (this is the default state of a model)\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass on train data using the forward() method inside\n",
        "    y_pred = model_0(x_train)\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 2. Calc the loss (how diff are our models predictions to the ground truth)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing"
      ],
      "metadata": {
        "id": "sD5A-PSZAGc6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}